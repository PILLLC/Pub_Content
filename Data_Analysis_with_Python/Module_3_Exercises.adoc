== Module {module-number}: Statistical Analysis

[grid=none,frame=none,cols="25%a,75%a"]
|===
|image::agenda.svg[align="left",pdfwidth=50%]|Upon completion of these exercises, students should be able to:

* Perform exploratory data analysis on a given dataset, including calculating descriptive statistics and visualizing distributions. _(Exercise {module-number}A)_ 
* Use Statsmodels to perform linear regression analysis and hypothesis testing on a dataset. _(Exercise {module-number}B)_ 
* Explore advanced statistical analysis techniques using Pingouin, including conducting correlation analysis and non-parametric tests. _(Exercise {module-number}C)_ 
* Conduct hypothesis tests and statistical computations using SciPy. _(Exercise {module-number}D)_ 
|===

<<<

=== Exercise {module-number}A - Perform exploratory data analysis on a given dataset, including calculating descriptive statistics and visualizing distributions.

Exploratory Data Analysis (EDA) involves understanding the data, identifying patterns, and extracting insights. Here's a step-by-step guide to performing EDA on a given dataset:

1. **Load the dataset:** Use pandas to load the dataset into a DataFrame.

2. **Inspect the dataset:** Display the first few rows (`df.head()`) to understand the structure of the data. Check for missing values (`df.info()`) and handle them if necessary.

3. **Descriptive statistics:** Calculate basic statistics such as mean, median, standard deviation, minimum, maximum, and quartiles using `df.describe()`.

4. **Visualize distributions:** Create visualizations to explore the distributions of numerical variables using histograms, box plots, and density plots. For categorical variables, use bar plots or pie charts.

5. **Explore relationships:** Use scatter plots, pair plots, or correlation matrices to understand the relationships between variables.

6. **Identify outliers:** Visualize and/or detect outliers using box plots or scatter plots.

7. **Feature engineering:** Create new features if necessary, based on domain knowledge or insights gained during exploration.

Let's illustrate these steps using a sample dataset:

[source,python]
----
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Load the dataset
df = pd.read_csv('your_dataset.csv')

# Step 2: Inspect the dataset
print("First few rows of the dataset:")
print(df.head())

print("\nDataset information:")
print(df.info())

# Step 3: Descriptive statistics
print("\nDescriptive statistics:")
print(df.describe())

# Step 4: Visualize distributions
# Histograms for numerical variables
df.hist(figsize=(10, 8))
plt.suptitle("Histograms of Numerical Variables")
plt.show()

# Box plots for numerical variables
plt.figure(figsize=(10, 6))
sns.boxplot(data=df)
plt.title("Box Plot of Numerical Variables")
plt.show()

# Bar plot for categorical variables
plt.figure(figsize=(8, 6))
sns.countplot(x='category', data=df)
plt.title("Count of Observations by Category")
plt.show()

# Step 5: Explore relationships
# Pair plot for numerical variables
sns.pairplot(df)
plt.title("Pair Plot of Numerical Variables")
plt.show()

# Heatmap of correlation matrix
plt.figure(figsize=(8, 6))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Matrix")
plt.show()

# Step 6: Identify outliers
# Box plot of numerical variables
plt.figure(figsize=(10, 6))
sns.boxplot(data=df[['numeric_column1', 'numeric_column2']])
plt.title("Box Plot of Numerical Variables")
plt.show()

# Step 7: Feature engineering (if necessary)

# Further analysis based on insights gained

# Save or display visualizations
----

Replace `'your_dataset.csv'` with the path to your dataset. This code provides a basic framework for performing exploratory data analysis. You can further customize the visualizations and analysis based on the specific characteristics of your dataset.

<<<

=== Exercise {module-number}B - Use Statsmodels to perform linear regression analysis and hypothesis testing on a dataset.
Below is an example code demonstrating how to perform linear regression analysis and hypothesis testing using Statsmodels on a dataset:

[source,python]
----
import pandas as pd
import numpy as np
import statsmodels.api as sm

# Load the dataset
data = pd.read_csv('your_dataset.csv')

# Prepare the data
X = data[['feature1', 'feature2']]  # Independent variables
y = data['target']  # Dependent variable

# Add a constant term to the independent variables (intercept term)
X = sm.add_constant(X)

# Fit the linear regression model
model = sm.OLS(y, X).fit()

# Print the summary statistics
print(model.summary())

# Perform hypothesis testing
# For example, test the significance of the coefficients
print("Hypothesis Testing:")
print("Test for feature1 coefficient:")
print("Null Hypothesis: Coefficient for feature1 is zero")
print("Alternative Hypothesis: Coefficient for feature1 is not zero")
print("p-value:", model.pvalues['feature1'])
print("Conclusion: Reject the null hypothesis if p-value < significance level (e.g., 0.05)")
----

Replace `'your_dataset.csv'` with the actual path to your dataset. This code performs the following steps:

1. Load the dataset into a DataFrame.
2. Prepare the data by separating the independent variables (features) and the dependent variable (target).
3. Add a constant term to the independent variables to fit the intercept term in the linear regression model.
4. Fit the Ordinary Least Squares (OLS) linear regression model using `sm.OLS()` and `.fit()`.
5. Print the summary statistics of the model, including coefficients, standard errors, t-values, p-values, and more.
6. Perform hypothesis testing on the coefficients to test their significance.

You can adjust the code according to your specific dataset and hypothesis testing requirements.

<<<

=== Exercise {module-number}C - Explore advanced statistical analysis techniques using Pingouin, including conducting correlation analysis and non-parametric tests.

Pingouin is a Python package that provides an extensive collection of statistical methods for scientific research. It offers various advanced statistical analysis techniques, including correlation analysis and non-parametric tests. Below is an example code demonstrating how to perform correlation analysis and non-parametric tests using Pingouin:

[source,python]
----
import pandas as pd
import pingouin as pg

# Load the dataset
data = pd.read_csv('your_dataset.csv')

# Correlation Analysis
# Pearson correlation coefficient and p-value
pearson_corr = pg.corr(data['variable1'], data['variable2'], method='pearson')
print("Pearson correlation coefficient:")
print(pearson_corr)

# Spearman correlation coefficient and p-value
spearman_corr = pg.corr(data['variable1'], data['variable2'], method='spearman')
print("\nSpearman correlation coefficient:")
print(spearman_corr)

# Kendall correlation coefficient and p-value
kendall_corr = pg.corr(data['variable1'], data['variable2'], method='kendall')
print("\nKendall correlation coefficient:")
print(kendall_corr)

# Non-parametric tests
# Wilcoxon signed-rank test
wilcoxon_test = pg.wilcoxon(data['variable1'], data['variable2'])
print("\nWilcoxon signed-rank test:")
print(wilcoxon_test)

# Mann-Whitney U test
mannwhitneyu_test = pg.mwu(data['variable1'], data['variable2'])
print("\nMann-Whitney U test:")
print(mannwhitneyu_test)
----

Replace `'your_dataset.csv'` with the actual path to your dataset. This code performs the following tasks:

1. Loads the dataset into a DataFrame.
2. Performs correlation analysis using Pearson, Spearman, and Kendall correlation coefficients.
3. Performs non-parametric tests including the Wilcoxon signed-rank test and Mann-Whitney U test.
4. Prints the results of each analysis.

You can adjust the code according to your specific dataset and analysis requirements. Additionally, Pingouin offers many more statistical methods and tests, so feel free to explore its documentation for more options and functionalities.

<<<

=== Exercise {module-number}D - Conduct hypothesis tests and statistical computations using SciPy.

[source,python]
----
import numpy as np
from scipy import stats

# Generate some sample data
np.random.seed(0)
sample1 = np.random.normal(loc=5, scale=2, size=100)  # Sample 1 with mean 5 and standard deviation 2
sample2 = np.random.normal(loc=4, scale=2, size=100)  # Sample 2 with mean 4 and standard deviation 2

# Conduct a t-test to compare means of two independent samples
t_statistic, p_value = stats.ttest_ind(sample1, sample2)
print("T-statistic:", t_statistic)
print("P-value:", p_value)

# Perform a chi-square test for independence
# Create a contingency table
observed = np.array([[20, 30], [15, 35]])  # Example contingency table
chi2_statistic, p_value, degrees_of_freedom, expected = stats.chi2_contingency(observed)
print("\nChi-square statistic:", chi2_statistic)
print("P-value:", p_value)
print("Degrees of freedom:", degrees_of_freedom)
print("Expected frequencies:\n", expected)

# Conduct a one-way ANOVA test
# Generate some additional sample data
group1 = np.random.normal(loc=10, scale=2, size=50)  # Group 1 with mean 10 and standard deviation 2
group2 = np.random.normal(loc=12, scale=2, size=50)  # Group 2 with mean 12 and standard deviation 2
group3 = np.random.normal(loc=14, scale=2, size=50)  # Group 3 with mean 14 and standard deviation 2
# Combine all groups
all_groups = [group1, group2, group3]
f_statistic, p_value = stats.f_oneway(*all_groups)
print("\nF-statistic:", f_statistic)
print("P-value:", p_value)
----

<<<