== Module {module-number}: Statistical Analysis
:imagesdir: images
:source-highlighter: rouge
:icons: font

image::PIL_Logo_2023.png[align="left", pdfwidth=25%]

{SP}

[discrete]
=== Learning Objectives



[grid=none,frame=none,cols="25%a,75%a"]
|===
|image::agenda.svg[align="left",pdfwidth=50%]|Upon completion of this module, students should be able to:

* Understand the principles of statistical analysis.
* Learn to use Statsmodels for regression analysis, hypothesis testing, and other statistical tasks.
* Explore advanced statistical analysis techniques using Pingouin.
* Learn to use SciPy for statistical computations and hypothesis testing.
|
|===

<<<
    
=== Lesson {module-number}.1: Principles of Statistical Analysis

[grid=none,frame=none,cols="25%a,75%a"]
|===
|image::bullseye.svg[align="left",pdfwidth=50%]|Statistical analysis is a fundamental component of data science and plays a crucial role in deriving meaningful insights from data. 

In this lesson, we'll explore the principles of statistical analysis and learn about key concepts and techniques used to analyze data and draw conclusions from it.
|
|===

{SP}

image::Principles of Statistical Analysisii.png[align="center",pdfwidth=25%]





ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* The image appears to show output from a Python environment, likely using the Pandas library, which is commonly used for data manipulation and analysis. It presents a dataset with a snippet of code that outputs the first few rows of a DataFrame, information about the DataFrame such as its class type, the number of entries, data types of the columns, and memory usage. It also includes descriptive statistics for three numerical columns, showing the count, mean, and standard deviation. This is a typical summary that analysts look at when first examining a dataset to understand its structure, contents, and basic statistical properties.
endif::[]

ifdef::artifact-type[]

---
* Statistical analysis forms the backbone of data science, offering essential tools and methodologies for extracting valuable insights from data.
* This lesson delves into the foundational principles of statistical analysis, providing learners with a comprehensive understanding of the underlying concepts and techniques.
* Learners will explore key statistical concepts, including probability distributions, hypothesis testing, and regression analysis, to gain proficiency in analyzing and interpreting data.
* Through practical examples and exercises, participants will apply statistical techniques to real-world datasets, honing their analytical skills and problem-solving abilities.

endif::artifact-type[]

<<<

==== Introduction to Statistical Analysis

[frame="none", grid="none, "cols="a,a"]
|===
|* Statistical analysis involves the collection, interpretation, and presentation of data to uncover patterns, relationships, and trends. 
* It encompasses a wide range of techniques for summarizing data, testing hypotheses, estimating parameters, and making predictions. 
* Statistical analysis helps researchers and analysts make informed decisions and draw reliable conclusions based on empirical evidence.|image::Introduction to Statistical Analysis.png[]
|===

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* The image displays a plot of Probability Density Functions (PDFs) for the petal length of three different species of Iris flowers: Setosa, Virginica, and Versicolor. Each species' PDF is plotted with a different color, and the curves indicate the distribution of petal lengths within each species. This type of visualization is helpful in statistics to understand the distribution and density of continuous data, and it's often used to compare different groups within a dataset.
endif::[]

ifdef::artifact-type[]

---
* Statistical analysis plays a crucial role in various fields, including science, business, healthcare, and social sciences, aiding in evidence-based decision-making and problem-solving.
* It involves both descriptive and inferential statistics, where descriptive statistics summarize data characteristics while inferential statistics draw conclusions about populations based on sample data.
* Statistical analysis techniques encompass a diverse array of methods, such as regression analysis, hypothesis testing, ANOVA (analysis of variance), and time series analysis, among others.

endif::artifact-type[]

<<<

==== Key Concepts in Statistical Analysis

[frame="none", grid="none, "cols="a,a"]
|===
|- **Descriptive Statistics**
- **Inferential Statistics**
- **Probability Theory**
- **Statistical Models**|image::Key Concepts in Statistical Analysis.png[]
|===

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* The image illustrates the cycle of statistical analysis. It shows the process starting from a population of interest from which data is produced. This data is then used for exploratory data analysis to uncover patterns, spot anomalies, and test hypotheses. The insights gained lead to probabilistic conclusions about the population, which in turn inform further inference. This cyclical process highlights the iterative nature of statistical analysis.
endif::[]

ifdef::artifact-type[]

---
* **Sampling Methods**: Sampling methods are techniques used to select a subset of data from a larger population for analysis. Common methods include random sampling, stratified sampling, and cluster sampling.
* **Parametric vs. Non-parametric Methods**: Statistical methods can be classified as parametric or non-parametric based on assumptions about the underlying data distribution. Parametric methods assume a specific distribution (e.g., normal distribution), while non-parametric methods do not make such assumptions.
* **Experimental Design**: Experimental design involves planning and conducting experiments to collect data in a systematic and controlled manner. It includes considerations such as sample size determination, randomization, and control of confounding variables.
* **Statistical Significance**: Statistical significance refers to the likelihood that an observed effect in a dataset is not due to chance. It is often assessed using hypothesis testing and p-values, with lower p-values indicating greater statistical significance.

endif::artifact-type[]

<<<

==== Principles of Statistical Analysis

[frame="none", grid="none, "cols="a,a"]
|===
|In this section, we'll cover some fundamental principles of statistical analysis:

**Principle 1: Define the Research Question**


**Principle 2: Choose the Right Data**


**Principle 3: Understand the Data Distribution**


**Principle 4: Apply Appropriate Statistical Techniques**


**Principle 5: Interpret Results Carefully**
|image::Principles of Statistical Analysis.png[]||
|===

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* The image appears to display a scatter plot with a linear regression line. 
endif::[]

ifdef::artifact-type[]

---
* **Principle 1: Define the Research Question**
   - Before embarking on any statistical analysis, it is imperative to define the research question or objective clearly. 
   - A well-defined research question guides the selection of appropriate statistical techniques and provides a framework for interpreting results accurately.

* **Principle 2: Choose the Right Data**
   - The selection of suitable data is paramount for conducting meaningful statistical analysis.
   - Ensure that the data chosen is pertinent to the research question, representative of the population of interest, and devoid of biases or errors.

* **Principle 3: Understand the Data Distribution**
   - A profound understanding of the distribution of data is crucial for selecting suitable statistical methods and ensuring accurate interpretation of results.

* **Principle 4: Apply Appropriate Statistical Techniques**
   - It is essential to choose statistical techniques that align with the type of data and research question at hand.

* **Principle 5: Interpret Results Carefully**
   - The interpretation of statistical findings necessitates meticulous attention to context, assumptions, and constraints.

endif::artifact-type[]

<<<

==== Conclusion

In conclusion, statistical analysis is a powerful tool for extracting insights from data and making informed decisions. 

By following fundamental principles and best practices in statistical analysis, researchers and analysts can conduct rigorous and reliable data analysis and contribute to evidence-based decision-making.

[NOTE]
**Hands-On Exercise:**
For hands-on experience, review and complete _Exercise 3A_ in the exercise guide for this course.

ifdef::artifact-type[]

---

===== Additional Resources

- "Introduction to Statistical Learning" by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani
- "The Art of Statistics: Learning from Data" by David Spiegelhalter
- Coursera: Statistics with R Specialization: https://www.coursera.org/specializations/statistics

endif::artifact-type[]

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* After allowing time for the hands-on exercise, transition to the next lesson in the module.

endif::[]

<<<

=== Lesson {module-number}.2: Regression Analysis and Hypothesis Testing with Statsmodels

[grid=none,frame=none,cols="25%a,75%a"]
|===
|image::bullseye.svg[align="left",pdfwidth=50%]|Regression analysis and hypothesis testing are essential techniques in statistical analysis for exploring relationships between variables and making inferences from data. 

In this lesson, we'll explore how to perform regression analysis and hypothesis testing using the Statsmodels library in Python.
|
|===

{SP}

image::Regression Analysis and Hypothesis Testing with Statsmodels.png[pdfwidth="30%", pdfheight="30%"]

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* The image displays the output of an OLS (Ordinary Least Squares) regression analysis.
endif::[]

ifdef::artifact-type[]

---
* Regression analysis is a statistical technique used to model and analyze the relationships between one or more independent variables (predictors) and a dependent variable (outcome).
* Hypothesis testing is a statistical method used to make inferences about population parameters based on sample data, allowing researchers to assess the significance of observed effects.
* Statsmodels is a Python library that provides classes and functions for performing various statistical analyses, including regression analysis and hypothesis testing.
* Participants will also explore hypothesis testing techniques using Statsmodels, including t-tests, ANOVA, and chi-square tests, to evaluate hypotheses and make informed decisions based on statistical evidence.
* Practical applications of regression analysis and hypothesis testing include predicting outcomes, identifying relationships between variables, testing research hypotheses, and making data-driven decisions in various domains such as finance, healthcare, and social sciences.

endif::artifact-type[]

<<<

==== Introduction to Statsmodels

[frame="none", grid="none, "cols="a,a"]
|===
|* Statsmodels is a Python library for statistical modeling and hypothesis testing. 
* It provides a wide range of tools for estimating and interpreting various statistical models, including linear regression, logistic regression, time series analysis, and more. 
* Statsmodels integrates seamlessly with other scientific computing libraries such as NumPy and Pandas, making it a powerful tool for data analysis in Python.|image::Introduction to Statsmodels.png[]
|===

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* The image seems to present output from a Generalized Linear Model (GLM) regression analysis using the Python Statsmodels library. This specific model uses the Gamma family with an inverse power link function, which is suitable for positive continuous data. The output includes the coefficients for each variable (`x1` through `x7`), their standard errors, z-scores, and associated p-values, which are used to infer the significance of predictors. With such results, one can assess the relationship between the predictors and the response variable, testing hypotheses about the data.
endif::[]

ifdef::artifact-type[]

---
* Statsmodels offers comprehensive support for conducting statistical modeling and hypothesis testing, encompassing various techniques beyond linear and logistic regression.
* Its extensive toolkit includes capabilities for time series analysis, generalized linear models, survival analysis, and nonparametric methods, among others, providing a broad spectrum of statistical analysis tools.
* Statsmodels boasts a user-friendly interface and intuitive API, facilitating straightforward model estimation, interpretation, and diagnostics for both novice and experienced users.
* Beyond its core functionality, Statsmodels continues to evolve, with ongoing development efforts aimed at enhancing performance, expanding capabilities, and improving user experience.

endif::artifact-type[]

<<<

==== Key Features of Statsmodels

[frame="none", grid="none, "cols="a,a"]
|===
|- **Linear Regression**
- **Hypothesis Testing**
- **Diagnostic Tests**
- **Model Visualization**
- **Integration with Pandas**|image::Key Features of Statsmodels.png[]
|===

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* The image likely shows a scatter plot comparing the results of a Generalized Linear Model (GLM) as implemented in two different software environments: Python's StatsModels and MATLAB. 
endif::[]

ifdef::artifact-type[]

---
* **Time Series Analysis**: Statsmodels offers extensive support for time series analysis, including classes and functions for modeling time series data, forecasting, and performing diagnostic tests.
* **Econometric Models**: Statsmodels includes a wide range of econometric models and methods for analyzing economic and financial data, such as autoregressive integrated moving average (ARIMA) models, vector autoregression (VAR) models, and panel data analysis.
* **Survival Analysis**: Statsmodels supports survival analysis, offering classes and functions for modeling time-to-event data, estimating survival curves, and conducting hypothesis tests in survival analysis.
* **Generalized Linear Models (GLM)**: In addition to linear regression, Statsmodels supports generalized linear models (GLM) for analyzing non-normal and non-linear data, including logistic regression, Poisson regression, and gamma regression.
* **Model Comparison and Selection**: Statsmodels provides tools for comparing and selecting between different models.

endif::artifact-type[]

<<<

==== Regression Analysis with Statsmodels

[frame="none", grid="none, "cols="a,a"]
|===
|In this section, we'll cover how to perform regression analysis using Statsmodels:

**Simple Linear Regression**
- Use Statsmodels to fit a simple linear regression model to data and interpret the results.
- Assess the statistical significance of the regression coefficients using hypothesis testing.
- Visualize the regression line and predicted values using matplotlib.

**Multiple Linear Regression**
- Extend simple linear regression to multiple linear regression models with multiple predictor variables.
- Interpret the coefficients of multiple regression models and assess their statistical significance.
- Use diagnostic tests and visualizations to evaluate the assumptions of multiple regression models.|image::Regression Analysis with Statsmodels.png[]
|===

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* The image appears to show a set of spectral data plotted as absorbance versus wavelength. Multiple overlaid lines could indicate different spectra obtained under varying conditions or from different samples. Such graphs are common in analytical chemistry, where they are used to analyze substance composition or concentration based on their absorbance patterns across different wavelengths.
endif::[]

ifdef::artifact-type[]

---
* Statsmodels offers robust capabilities for performing regression analysis, facilitating the exploration of relationships between variables in datasets.
* Simple linear regression, a fundamental technique in regression analysis, involves fitting a linear model to data with a single predictor variable.
* Through hypothesis testing, Statsmodels enables users to assess the statistical significance of regression coefficients, aiding in the interpretation of model results.
* Visualizations created using matplotlib complement regression analysis by illustrating the regression line and predicted values, enhancing understanding and interpretation.
* Multiple linear regression expands upon simple linear regression by incorporating multiple predictor variables into the model, allowing for more comprehensive analysis of relationships between variables.
* Interpretation of coefficients in multiple regression models involves understanding the impact of each predictor variable on the outcome variable while considering the effects of other variables in the model.
* Diagnostic tests and visualizations serve as valuable tools for evaluating the assumptions underlying multiple regression models, helping to ensure the validity of model results and conclusions.

endif::artifact-type[]

<<<

==== Hypothesis Testing with Statsmodels

[frame="none", grid="none, "cols="a,a"]
|===
|In this section, we'll cover how to perform hypothesis testing using Statsmodels:

**Testing Model Coefficients**

**Goodness-of-Fit Tests**

|image::Hypothesis Testing with Statsmodels.png[]
|===

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* The image illustrates the outcomes of hypothesis testing in statistics. It shows a 2x2 matrix that categorizes the outcomes based on whether the null hypothesis (H0) is actually true or false and whether the test leads to accepting or rejecting H0.
endif::[]

ifdef::artifact-type[]

---
* Statsmodels facilitates hypothesis testing by allowing users to assess the statistical significance of coefficients in regression models.
* T-tests and F-tests are commonly used for hypothesis testing, enabling evaluation of individual coefficients and overall model fit, respectively.
* Interpretation of hypothesis test results involves analyzing p-values and confidence intervals to make informed decisions about the significance of model coefficients.
* Goodness-of-fit tests, including metrics like the R-squared statistic and the F-statistic, assess the overall fit of regression models.
* By interpreting the results of goodness-of-fit tests, analysts can gauge the explanatory power of regression models and determine their effectiveness in capturing the variability of the data.

endif::artifact-type[]

<<<

==== Conclusion

In conclusion, Statsmodels is a powerful library for regression analysis and hypothesis testing in Python. 

By leveraging its features and capabilities, analysts can explore relationships between variables, test hypotheses, and make informed decisions based on empirical evidence.

[NOTE]
**Hands-On Exercise:**
For hands-on experience, review and complete _Exercise 3B_ in the exercise guide for this course.


ifdef::artifact-type[]

---

===== Additional Resources

- Statsmodels Documentation: https://www.statsmodels.org/stable/index.html
- "Regression Analysis: A Constructive Critique" by Richard B. Darlington
- Coursera: Regression Models: https://www.coursera.org/learn/regression-models

endif::artifact-type[]

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* After allowing time for the hands-on exercise, transition to the next lesson in the module.

endif::[]

<<<

=== Lesson {module-number}.3: Advanced Statistical Analysis Techniques with Pingouin

[grid=none,frame=none,cols="25%a,75%a"]
|===
|image::bullseye.svg[align="left",pdfwidth=50%]|Pingouin is a Python library for statistical analysis built on top of Pandas and SciPy. It provides a wide range of advanced statistical tests and functions for exploring relationships between variables and conducting hypothesis testing. 

In this lesson, we'll explore how to use Pingouin for advanced statistical analysis techniques.
|
|===

{SP}

image::Advanced Statistical Analysis Techniques with Pingouin.png[pdfwidth="40%", pdfheight="40%"]

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* The image presents the results of various statistical tests and correlation coefficients. The Pearson, Spearman, and Kendall tests indicate a perfect positive correlation (r = 1.0) between two variables, with the p-values suggesting significant results for the Spearman and Kendall tests. The Wilcoxon signed-rank test and the Mann-Whitney U test show their respective statistics and p-values, with the Wilcoxon test indicating a p-value that suggests significance, whereas the Mann-Whitney U test does not show a significant result (p > 0.05). 
endif::[]


ifdef::artifact-type[]

---
* Pingouin is not only built on top of Pandas and SciPy but also integrates seamlessly with other Python libraries commonly used in data analysis and machine learning workflows.
* In addition to basic statistical tests, Pingouin offers advanced statistical methods such as repeated measures ANOVA, mixed-design ANOVA, and Bayesian correlation analysis.
* Pingouin provides a user-friendly interface for conducting statistical analyses, making it accessible to users with varying levels of statistical expertise.
* The library includes comprehensive documentation and examples, facilitating the learning and adoption of advanced statistical techniques.

endif::artifact-type[]

<<<

==== Introduction to Pingouin

[frame="none", grid="none, "cols="a,a"]
|===
|* Pingouin is designed to simplify the process of conducting advanced statistical analysis in Python. 
* It offers a user-friendly interface and integrates seamlessly with Pandas DataFrames, making it easy to perform complex statistical tests and interpret the results. 
* Pingouin provides support for various statistical tests, including parametric and non-parametric tests, correlation analysis, and effect size estimation.|
|===

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* This note only apears in the instructor guide.
endif::[]

ifdef::artifact-type[]

---
* Pingouin streamlines advanced statistical analysis in Python by providing an intuitive and accessible framework.
* Its seamless integration with Pandas DataFrames facilitates the execution of complex statistical tests directly on structured data, enhancing workflow efficiency.
* Pingouin offers a comprehensive range of statistical tests, encompassing parametric and non-parametric tests, correlation analysis, and effect size estimation, catering to diverse analytical needs.
* In addition to its statistical testing capabilities, Pingouin provides functionalities for descriptive statistics, distribution fitting, and power analysis, empowering users with a comprehensive statistical toolkit.
* Pingouin prioritizes transparency and reproducibility by implementing best practices in statistical analysis and providing detailed documentation and tutorials to guide users through the analysis process.

endif::artifact-type[]

<<<

==== Key Features of Pingouin

[frame="none", grid="none, "cols="a,a"]
|===
|- **Comprehensive Test Suite**
- **Effect Size Estimation**
- **Power Analysis**
- **Robust Statistical Tests**
- **Visualization Tools**|
|===

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* This note only apears in the instructor guide.
endif::[]

ifdef::artifact-type[]

---
* **Assumption Testing**: Pingouin provides functions for testing assumptions required for various statistical tests, such as normality and homogeneity of variances.
* **Non-Parametric Tests**: In addition to parametric tests, Pingouin offers a wide range of non-parametric tests for analyzing data that does not meet the assumptions of parametric tests.
* **Multi-Comparison Correction**: Pingouin supports multiple comparison correction methods to account for the increased risk of Type I errors when conducting multiple comparisons.
* **Integration with Pandas**: Pingouin seamlessly integrates with Pandas DataFrames, allowing users to perform statistical analysis directly on Pandas data structures.
* **Documentation and Support**: Pingouin provides comprehensive documentation and user support, including tutorials, examples, and a dedicated community forum for users to seek assistance and share insights.

endif::artifact-type[]

<<<

==== Advanced Statistical Analysis Techniques

[frame="none", grid="none, "cols="a,a"]
|===
|In this section, we'll cover some advanced statistical analysis techniques using Pingouin:

**Parametric and Non-Parametric Tests**

**Correlation Analysis**

**Effect Size Estimation**

|image::Advanced Statistical Analysis Techniques with Pingouin.png[pdfwidth=50%, pdfheight=50%]
|===

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* This note only appears in the instructor guide.
endif::[]


ifdef::artifact-type[]

---
* **Parametric and Non-Parametric Tests:**
  - Utilize Pingouin to conduct parametric tests, including t-tests and ANOVA, which are suitable for comparing means between groups assuming certain distributional properties.
  - Employ non-parametric tests, such as the Wilcoxon signed-rank test and the Kruskal-Wallis test, when data violate the assumptions of normality, ensuring robust statistical analysis in diverse scenarios.

* **Correlation Analysis:**
  - Leverage Pingouin to compute various correlation coefficients, such as Pearson's correlation coefficient and Spearman's rank correlation coefficient, to quantify the strength and direction of relationships between variables.
  - Assess the significance of correlations using Pingouin and perform hypothesis tests to determine whether observed correlations are statistically meaningful, providing insights into the relationships within datasets.

* **Effect Size Estimation:**
  - Utilize Pingouin to calculate effect sizes for different statistical tests, including Cohen's d for t-tests and eta-squared for ANOVA, aiding in the interpretation of statistical findings.

endif::artifact-type[]

<<<

==== Conclusion

In conclusion, Pingouin is a valuable tool for conducting advanced statistical analysis in Python. 

By leveraging its features and capabilities, analysts can explore relationships between variables, test hypotheses, and quantify the practical significance of statistical findings with ease.

[NOTE]
**Hands-On Exercise:**
For hands-on experience, review and complete _Exercise 3C_ in the exercise guide for this course.

ifdef::artifact-type[]

---

===== Additional Resources

- Pingouin Documentation: https://pingouin-stats.org/
- "Introduction to Statistical Learning" by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani
- Coursera: Statistics with Python Specialization: https://www.coursera.org/specializations/statistics-with-python


endif::artifact-type[]

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* After allowing time for the hands-on exercise, transition to the next lesson in the module.

endif::[]

<<<

=== Lesson {module-number}.4: Statistical Computations and Hypothesis Testing with SciPy

[grid=none,frame=none,cols="25%a,75%a"]
|===
|image::bullseye.svg[align="left",pdfwidth=50%]|SciPy is a powerful library for scientific computing in Python, providing a wide range of functions for numerical optimization, interpolation, integration, and statistical analysis. 

In this lesson, we'll explore how to use SciPy for statistical computations and hypothesis testing.
|
|===

{SP}

image::Statistical Computations and Hypothesis Testing with SciPy.png[pdfwidth=15%, pdfheight=15%]

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* The image shows a scatter plot with a curve fit, likely using data from an experiment or a simulation. The plot is titled "Fitting two Gaussians," which suggests that the data has been modeled using a combination of two Gaussian functions.

endif::[]

ifdef::artifact-type[]

---
* SciPy offers a comprehensive suite of statistical functions, including descriptive statistics, probability distributions, and hypothesis testing, empowering users to conduct a wide range of statistical analyses.
* Beyond basic statistical computations, SciPy provides advanced functionality for fitting statistical models, conducting regression analysis, and performing multivariate statistical tests.
* The library's integration with NumPy makes it seamless to manipulate arrays and matrices, facilitating data preparation and preprocessing tasks required for statistical analysis.
* In addition to statistical functions, SciPy provides tools for numerical optimization, interpolation, and integration, making it a versatile toolkit for scientific computing tasks beyond statistical analysis.


endif::artifact-type[]

<<<

==== Introduction to SciPy

[frame="none", grid="none, "cols="a,a"]
|===
|* SciPy is built on top of NumPy and provides additional functionality for scientific computing tasks. 
* It includes modules for optimization, interpolation, integration, Fourier transforms, signal processing, linear algebra, and more. 
* The `scipy.stats` module, in particular, contains functions for statistical analysis, probability distributions, and hypothesis testing.|image::Introduction to SciPy.png[pdfwidth=50%, pdfheight=50%]
|===

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* The image is a logo representing the Python programming language, characterized by the stylized depiction of a snake, which is Python's mascot. Python is a popular programming language known for its simplicity and readability, widely used for various applications including web development, automation, data analysis, and scientific computing.

endif::[]

ifdef::artifact-type[]

---
* SciPy extends the capabilities of NumPy by offering a wide range of additional functionality tailored for scientific computing tasks.
* Its modules cover a broad spectrum of scientific computing domains, including optimization, interpolation, integration, Fourier transforms, signal processing, and linear algebra.
* The `scipy.stats` module is a powerful tool for statistical analysis, providing functions for calculating descriptive statistics, probability distributions, and performing hypothesis testing.
* SciPy's integration with other scientific Python libraries, such as Matplotlib and Pandas, enhances its usability and interoperability within the Python scientific computing ecosystem.
* It provides efficient and robust implementations of numerical algorithms, making it a valuable resource for researchers, engineers, and data scientists working on complex computational tasks.

endif::artifact-type[]


<<<

==== Key Features of SciPy

[frame="none", grid="none, "cols="a,a"]
|===
|- **Statistical Functions**
- **Integration and Optimization**
- **Signal and Image Processing**
- **Interpolation and Splines**|image::Key Features of SciPy.png[]
|===

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* The image depicts two plots related to signal processing, which is a common application of the SciPy library in Python. The top plot shows a damped oscillation, with the amplitude decreasing over time, indicative of a damping effect in a physical system. The bottom plot shows the spectrum of the damped oscillator obtained through Fast Fourier Transform (FFT), highlighting the predominant frequency of the oscillation. This type of analysis is useful in engineering and physics to understand the behavior of systems and signals over time and frequency.
endif::[]

ifdef::artifact-type[]

---
* **Linear Algebra**: In addition to its extensive statistical capabilities, SciPy offers robust support for linear algebra operations, including matrix manipulation, eigenvalue computation, and singular value decomposition (SVD).
* **Sparse Matrix Support**: SciPy includes efficient data structures and algorithms for handling sparse matrices, enabling efficient computation and storage of large, sparse datasets commonly encountered in scientific computing.
* **Integration with NumPy**: SciPy seamlessly integrates with NumPy, enhancing its functionality by providing additional mathematical and scientific functions and algorithms built on top of NumPy's array manipulation capabilities.
* **Differential Equations**: SciPy features modules for solving ordinary differential equations (ODEs), partial differential equations (PDEs), and differential algebraic equations (DAEs), enabling simulation and modeling of dynamic systems in various scientific and engineering domains.

endif::artifact-type[]

<<<

==== Statistical Computations with SciPy

[frame="none", grid="none, "cols="a,a"]
|===
|In this section, we'll cover some common statistical computations using SciPy:

**Descriptive Statistics**

**Probability Distributions**

|image::Statistical Computations with SciPy.png[]
|===

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* The image shows the output of a Python program that seems to be using the Pandas library to display a DataFrame's content and descriptive statistics. The DataFrame contains four columns with integer and object (likely string) data types.
endif::[]

ifdef::artifact-type[]

---
* **Hypothesis Testing**
- Perform hypothesis testing using SciPy to compare sample means, proportions, variances, and other parameters against predefined values or between groups.
- Conduct a wide range of statistical tests, including t-tests, chi-square tests, ANOVA, and non-parametric tests like Mann-Whitney U test and Kolmogorov-Smirnov test.

* **Correlation and Regression Analysis**
- Compute correlation coefficients (e.g., Pearson correlation, Spearman correlation) to quantify the relationship between variables.
- Conduct linear and nonlinear regression analysis to model the relationship between variables and make predictions based on observed data.

* **Time Series Analysis**
- Use SciPy for time series analysis tasks such as autocorrelation analysis, spectral analysis, and periodogram estimation.

endif::artifact-type[]

<<<

==== Hypothesis Testing with SciPy

[frame="none", grid="none, "cols="a,a"]
|===
|In this section, we'll cover hypothesis testing techniques using SciPy:

**Parametric Tests**


**Non-Parametric Tests**
|image::Hypothesis Testing with SciPy.png[]
|===

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* The image depicts a hypothesis testing scenario using a normal distribution. It shows a calculation of a z-score, which is used to determine the p-value for a hypothesis test. The sample mean (\(\bar{x}\)) is 3.2, with a population mean (\(\mu\)) of 3 and a standard error (SE) of 0.246. The calculated z-score is 0.81, resulting in a p-value of 0.209. Since the p-value is greater than the common alpha level of 0.05, the conclusion is not to reject the null hypothesis (\(H_0\)). This implies that there isn't enough evidence to say the true mean differs from 3, based on the sample data.
endif::[]

ifdef::artifact-type[]

---
* Hypothesis testing techniques using SciPy enable researchers to make informed decisions based on statistical evidence.
* Parametric tests, facilitated by functions in the `scipy.stats` module, allow for hypothesis testing concerning population means, variances, proportions, and correlations.
* The use of parametric tests like t-tests, ANOVA, and linear regression relies on assumptions about the underlying distribution of the data, making them suitable for normally distributed data.
* Non-parametric tests, such as the Wilcoxon signed-rank test, Mann-Whitney U test, and Kruskal-Wallis test, provide alternatives for comparing distributions without requiring assumptions about their underlying distribution.
* Non-parametric tests are robust and applicable to a wide range of data distributions, making them particularly useful when data do not meet the assumptions of parametric tests.
* Understanding both parametric and non-parametric hypothesis testing techniques equips researchers with a comprehensive toolkit for analyzing data and drawing valid conclusions.

endif::[]

<<<

==== Conclusion

In conclusion, SciPy is a versatile library for statistical computing and hypothesis testing in Python. 

By leveraging its rich set of functions and modules, analysts can perform a wide range of statistical computations and conduct hypothesis tests to make data-driven decisions.

[NOTE]
**Hands-On Exercise:**
For hands-on experience, review and complete _Exercise 3D_ in the exercise guide for this course.

ifdef::artifact-type[]

---

===== Additional Resources

- SciPy Documentation: https://docs.scipy.org/doc/scipy/
- "Python for Data Analysis" by Wes McKinney
- Coursera: Applied Data Science with Python Specialization: https://www.coursera.org/specializations/data-science-python

endif::artifact-type[]

ifeval::["{artifact-type}" == "IG"]
---
*Instructor note:* After allowing time for the hands-on exercise, transition to the next lesson in the module.

endif::[]